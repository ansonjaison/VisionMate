# VisionMate 👓🧠

> **Empowering the Visually Impaired with AI-Driven Smart Glasses**

VisionMate is an ongoing AI-powered wearable project designed to enhance the lives of visually impaired individuals by providing real-time environmental awareness and navigational assistance. The system integrates computer vision, voice control, and smart navigation into a pair of intelligent glasses to promote greater independence, safety, and confidence.

---

## 🚀 Project Goal

To build a compact, affordable, and intuitive smart glass system that assists visually impaired users by:
- Detecting obstacles in real-time
- Reading and vocalizing text from the environment (signboards, boards, etc.)
- Guiding users to predefined locations via voice-based GPS navigation
- Supporting gesture-based interaction (single/double tap) for ease of use

---

## 🧠 Core Features

- 🎯 **Object Detection** – Real-time identification of obstacles using a mounted camera
- 🗺️ **Voice Navigation** – GPS-based route guidance to saved locations (e.g., Home, Medical Shop)
- 📖 **Text Recognition** – Reads aloud environmental texts and signboards using OCR
- 🎤 **Voice Command Input** – Hands-free operation via simple spoken commands
- ✨ **Gesture Support** – Tap-based interactions for triggering actions

---

## 📥 Inputs Required

- Live video feed from the glasses-mounted camera
- Predefined location coordinates (Home, Medical Shop, etc.)
- User voice commands
- Tap/gesture inputs
- Text from surroundings (labels, signs)

---

## 🎯 Expected Output

- Obstacle detection alerts
- Text-to-speech audio reading of signs and boards
- Voice-guided directions to target locations
- A lightweight, low-cost, user-friendly assistive wearable device

---

## 🛠️ Technology Stack

### 🔧 Hardware
- Camera with onboard processing unit
- TWS (True Wireless Stereo) Earphones
- Battery-powered portable unit

### 💻 Software
- **React Native** – Frontend/mobile interface
- **Python** – Backend logic and integrations
- **YOLO** – Real-time object detection
- **Tesseract OCR** – Text recognition
- **pyttsx3** – Text-to-speech conversion
- **MapBox** – GPS and route mapping

---

## 🧪 Current Status

This repository is currently under active development by Group 6 of S7 CSE B at VJCET. We're in the early implementation phase, laying the foundations for hardware integration, software architecture, and model training.

Stay tuned for updates and contributions!
